{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Explanation of the alignment procedure\n",
    "### for aligning very long audio sequences to very long text sequences\n",
    "\n",
    "This notebook describes the code for aligning long audio files to long text sequences using Huggingface Transformers toolkit.\n",
    "\n",
    "More precisely, we have the following inputs:\n",
    "* a long audio file (this can be anything from a few minutes, to a few hours, to a whole day of audio)\n",
    "* a text that contains the transcripts of the audio file\n",
    "\n",
    "On output we expect to get:\n",
    "* timecodes of portions of text to the portions of audio - word level timings\n",
    "\n",
    "Keeping in mind that:\n",
    "* audio can contain speech and events that aren't in the transcription\n",
    "* transcripts can contain text that isn't in the audio\n",
    "\n",
    "The sources of these discrepancies can be:\n",
    "* the transcript can be much larger than the speech contained in audio - in other words, we can have one large file with transcripts of many audio files and this is acceptable for this project - we only use what we need\n",
    "* the audio doesn't have to be transcribed with 100% recall or precision - transcribers make mistakes, not everything gets transcribed - this is all fine and we take it into account\n",
    "* the alignment process can produce errors - we have a procedure that allows for reviewing results and deciding on mitigation procedures after all the automation is complete\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from src.align import align, fix_times, save_ali_to_textgrid, convert_ali_to_segments\n",
    "from src.data_loaders import load_reco, load_audio, extract_audio\n",
    "from src.matching import Matcher\n",
    "from src.recognize import recognize"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T20:59:00.336967255Z",
     "start_time": "2023-07-21T20:58:59.081349798Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we define a couple of paths to local resources:\n",
    "* `audio_file` - the audio file containing the speech we wish to align to\n",
    "* `text_file` - the file containing all the transcripts - needs to contain text only and ideally should be normalized\n",
    "* `asr_model` - Huggingface hub name or path to the speech recognition model used to process the files\n",
    "\n",
    "These files are created throughout the procedure:\n",
    "* `reco_file`  - this file is the result of the initial speech recognition process\n",
    "* `textgrid_file`  - this file contains the final alignment openable in Praat and similar programs\n",
    "* `segs_file`  - this file contains the aligned segments useful for debugging and analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "audio_file = Path('data/1. posiedzenie Sejmu IX kadencji - dzień drugi [ZAPIS TRANSMISJI] [bM7-TmS16HY].wav')\n",
    "text_file = Path('data/ParlaMint-PL_2019-11-13-sejm-01-2.norm.txt')\n",
    "asr_model = 'asr_model'\n",
    "reco_file = Path('data/reco.json')\n",
    "textgrid_file = Path('data/out.TextGrid')\n",
    "segs_file = Path('data/segs.json')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T20:59:00.337232683Z",
     "start_time": "2023-07-21T20:59:00.325037187Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1 - Speech recognition\n",
    "\n",
    "The first step is to get any kind of speech recognition output that we can then use to align to actual transcripts.\n",
    "\n",
    "Since this process can be expensive, we will save the result immediately to a file. If the file exists, we don't have to run it again.\n",
    "\n",
    "It's also a good idea to restart the notebook kernel after running this cell in order to release memory on the GPU. Huggingface doesn't have a convenient method of releasing reserved resources and terminating the process is the simplest and most elegant way to achieve this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if not reco_file.exists():\n",
    "    reco = recognize(audio_file, asr_model, batch_size=4)\n",
    "    with open(reco_file, 'w') as f:\n",
    "        json.dump(reco, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T20:59:00.337342207Z",
     "start_time": "2023-07-21T20:59:00.327399760Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we re-load the above saved file. In the case of this demo, this will contain words belonging to only one recording, but theoretically you could recognize many recordings at once and the file would contain all of them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-21T20:59:00.337537185Z",
     "start_time": "2023-07-21T20:59:00.329984751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words per recording:\n",
      "{'1. posiedzenie Sejmu IX kadencji - dzień drugi [ZAPIS TRANSMISJI] [bM7-TmS16HY]': 2701}\n"
     ]
    }
   ],
   "source": [
    "words = load_reco(reco_file)\n",
    "\n",
    "print('Number of words per recording:')\n",
    "print({x: len(y) for x, y in words.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we will first get the utterance id of the single file in question and then extract some 100 words in the file. The idea of the procedure is to work in chunks to optimize the resources required for processing. We will first demonstrate the whole procedure on a single chunk and later show how to process the whole file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk len: 54.260000000000105s\n",
      "Chunk text:\n",
      "legitymację jeszcze moment dobrze to jeszcze chwileczkę po czekamy ale proszę u widzę że wszyscy mamy kartę do głosowania w związku z tym poddam ten wniosek pod głosowanie kto z pań i panów posłów jest za ogłoszeniem przerwy w obradach proszę o podniesienie ręki naciśnięcie przycisku kto jest przeciw kto się wstrzymał os państwa jest za zero to jest przeciw kto się wstrzymał głosowało czterystu czterdziestu dwóch posłów za było stu osiemdziesięciu dziewięciu przeciw dwustu czterdziestu siedmiu sześciu się wstrzymało wniosek przepadły nie i panowie posłowie prezydium sejmu przedłożyło projekt uchwały w sprawie ustalenia liczby członków komisji do spraw służb\n"
     ]
    }
   ],
   "source": [
    "utt_id = list(words.keys())[0]\n",
    "words_chunk = words[utt_id][300:400]\n",
    "\n",
    "print(f'Chunk len: {words_chunk[-1].end - words_chunk[0].start}s')\n",
    "text = ' '.join([x.text for x in words_chunk])\n",
    "print(f'Chunk text:\\n{text}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T20:59:00.384251669Z",
     "start_time": "2023-07-21T20:59:00.339134140Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2 - matching reco text to transcription\n",
    "\n",
    "We begin by creating a `Matcher` object. This object requires the text from the transcript file on initialization and can later be used to match various audio file speech recognition results to it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "word_seq = []\n",
    "with open(text_file) as f:\n",
    "    for l in f:\n",
    "        tok = l.strip().split()\n",
    "        word_seq.extend(tok)\n",
    "\n",
    "matcher = Matcher(word_seq)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T20:59:00.384392390Z",
     "start_time": "2023-07-21T20:59:00.381426259Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the beginning we match the above 100 word text to the whole transcript in a rough manner. This is done by making a histogram of the recognized word sequence and matching it to the histogram of the sliding window of same length across the whole transcript - akin to the BOW model of. A list of candidates that are sufficiently similar are returned at output. This can be controlled by the optional `threshold` argument."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33 potential locations for the above text.\n"
     ]
    }
   ],
   "source": [
    "locs = matcher._initial_match(text)\n",
    "print(f'Found {len(locs)} potential locations for the above text.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T20:59:00.384541986Z",
     "start_time": "2023-07-21T20:59:00.381602160Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "All the potential candidates are then compared to the original text using the Levenshtein distance method. This gives the exact score of all the differences between the two texts. That method is much more accurate, but also considerably more expensive than the one used in the inital match above. On output, we get both the best location and the difference between the two texts. The distance of 0 means the texts are identical. The higer the value to worse the match."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The location with minimum Levenshtein distance is 175 and that distance is 207.\n"
     ]
    }
   ],
   "source": [
    "min_i, min_d = matcher._find_min_diff(locs, text)\n",
    "print(f'The location with minimum Levenshtein distance is {min_i} and that distance is {min_d}.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T20:59:00.384680608Z",
     "start_time": "2023-07-21T20:59:00.381765368Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, the above method will only give us a starting location of the two texts, but given the nature of the speech recognition output and the transcript, these don't have to match in length. That is why we look for identically matching words to align the texts and reject any insertions/deletions at the beginning and the end of the sequence. The result is a set of two tuples containing both the begining and end of the speech recognition as well as the transcription portion of the text."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best matching sequence is between 1 and 100 in the recognized text and 181 and 275 in the reference corpus.\n"
     ]
    }
   ],
   "source": [
    "(hb, he), (rb, re) = matcher._find_matching_seq(text, min_i)\n",
    "\n",
    "print(f'The best matching sequence is between {hb} and {he} in the recognized text '\n",
    "      f'and {min_i + rb} and {min_i + re} in the reference corpus.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T20:59:00.384833933Z",
     "start_time": "2023-07-21T20:59:00.381954003Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Having all that we can now match the transcription text to the ASR text which allows us also to get the time location of the transcription chunk within the audio file:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position of the text in audio file data/1. posiedzenie Sejmu IX kadencji - dzień drugi [ZAPIS TRANSMISJI] [bM7-TmS16HY].wav is between seconds 659.848 and 711.816.\n",
      "Recognized text:\n",
      "jeszcze moment dobrze to jeszcze chwileczkę po czekamy ale proszę u widzę że wszyscy mamy kartę do głosowania w związku z tym poddam ten wniosek pod głosowanie kto z pań i panów posłów jest za ogłoszeniem przerwy w obradach proszę o podniesienie ręki naciśnięcie przycisku kto jest przeciw kto się wstrzymał os państwa jest za zero to jest przeciw kto się wstrzymał głosowało czterystu czterdziestu dwóch posłów za było stu osiemdziesięciu dziewięciu przeciw dwustu czterdziestu siedmiu sześciu się wstrzymało wniosek przepadły nie i panowie posłowie prezydium sejmu przedłożyło projekt uchwały w sprawie ustalenia liczby członków komisji do spraw służb\n",
      "Reference text:\n",
      "jeszcze moment jeszcze moment dobrze to jeszcze chwileczkę poczekamy ale proszę widzę że wszyscy mamy już karty do głosowania w związku z tym poddam ten wniosek pod głosowanie kto z pań i panów posłów jest za ogłoszeniem przerwy w obradach zechce podnieść rękę i nacisnąć przycisk kto jest przeciw kto się wstrzymał głosowało czterysta czterdzieści dwa posłów za było sto osiemdziesiąt dziewięć przeciw dwieście czterdzieści siedem sześć się wstrzymało wniosek przepadł został odrzucony przegrali brawo brawo panie i panowie posłowie prezydium sejmu przedłożyło projekt uchwały w sprawie ustalenia liczby członków komisji do spraw służb\n"
     ]
    }
   ],
   "source": [
    "hyp_text = ' '.join(text.split()[hb:he])\n",
    "hyp_tb = words_chunk[hb].start\n",
    "hyp_te = words_chunk[he - 1].end\n",
    "ref_text = matcher.get_corpus_chunk(min_i + rb, min_i + re)\n",
    "\n",
    "print(f'Position of the text in audio file {audio_file} is between seconds {hyp_tb} and {hyp_te}.')\n",
    "print(f'Recognized text:\\n{hyp_text}')\n",
    "print(f'Reference text:\\n{ref_text}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T20:59:00.385029841Z",
     "start_time": "2023-07-21T20:59:00.382221213Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can then extract the audio within this segment. Now, this audio can also contain lots of silence which affects the performance of the alignment below. That is why we extract only the portions of the audio that match the words recognized by the ASR. This should contain all the audio that contains any speech within this segment.\n",
    "\n",
    "We also get the bit-mask matching the extracted segments. This will allow us to recreate the times in the original file, before removing the silences."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the extracted segment is 35.7s.\n"
     ]
    }
   ],
   "source": [
    "audio = load_audio(audio_file)\n",
    "seg, mask = extract_audio(audio['input_values'], words_chunk[hb:he], audio['samp_freq'])\n",
    "\n",
    "print(f'The length of the extracted segment is {len(seg) / audio[\"samp_freq\"]}s.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T20:59:00.481910478Z",
     "start_time": "2023-07-21T20:59:00.382436561Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3 - Re-alignment\n",
    "\n",
    "The above text matching procedure only gave us the beginning and end of the whole segment. If we want to get a more accurate alignment we need to re-align all the words from the reference transcription to the audio. Fortunately, this procedure is quite robust given the limited number of words and length of audio extracted above.\n",
    "\n",
    "It is worth noting, however, that any errors and inaccuracies in the transcript will cause unexpected behavior in the final output.\n",
    "\n",
    "Note that this method accepts a whole sequence of audio/text pairs. Here we only have one, so we will put both in a single element list each."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/21/2023 22:59:00 [INFO] - Loading models...\n",
      "07/21/2023 22:59:13 [INFO] - Loading data...\n",
      "07/21/2023 22:59:13 [INFO] - Loaded 1 files!\n",
      "07/21/2023 22:59:13 [INFO] - Processing labels...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e69ebfb734704aa78824848273c2ddfd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/21/2023 22:59:13 [INFO] - Total audio length: 35.70s == 0.60min == 0.01h\n",
      "07/21/2023 22:59:13 [INFO] - Splitting data into chunks...\n",
      "07/21/2023 22:59:13 [WARNING] - Found cached dataset generator (/home/guest/.cache/huggingface/datasets/generator/default-0af7a33d18fb8d11/0.0.0)\n",
      "07/21/2023 22:59:13 [INFO] - Divided into 8 chunks!\n",
      "07/21/2023 22:59:13 [INFO] - Processing chunks using the W2V2 model...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/8 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5612609227346cb94a89223bc61ee74"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/21/2023 22:59:24 [INFO] - Merging chunks back into files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 15.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/21/2023 22:59:25 [INFO] - Performing forced alignment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ff60478b06b4e85a310c9ee1aa7c9bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/21/2023 22:59:25 [INFO] - Saving output...\n",
      "07/21/2023 22:59:25 [INFO] - Done!\n",
      "07/21/2023 22:59:25 [INFO] - Took 12.44s == 0.21min == 0.00h\n"
     ]
    }
   ],
   "source": [
    "ali = align(asr_model, [seg], [ref_text])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T20:59:25.474470253Z",
     "start_time": "2023-07-21T20:59:00.480873164Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is what the result looks like. It's a list of words, with a begin/end timestamp for each one. Note that the times provided are within the extracted segment only. To get the times that match the original file, we need to make some corrections."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "{'audio_0000': [{'text': 'jeszcze',\n   'timestamp': [0.019999999552965164, 0.1599999964237213]},\n  {'text': 'moment', 'timestamp': [0.18000000715255737, 0.30000001192092896]},\n  {'text': 'jeszcze', 'timestamp': [0.3199999928474426, 0.47999998927116394]},\n  {'text': 'moment', 'timestamp': [0.5199999809265137, 0.7599999904632568]},\n  {'text': 'dobrze', 'timestamp': [0.800000011920929, 1.2200000286102295]},\n  {'text': 'to', 'timestamp': [1.2599999904632568, 1.3200000524520874]},\n  {'text': 'jeszcze', 'timestamp': [1.340000033378601, 1.5]},\n  {'text': 'chwileczkę',\n   'timestamp': [1.5199999809265137, 1.8799999952316284]},\n  {'text': 'poczekamy', 'timestamp': [1.940000057220459, 2.559999942779541]},\n  {'text': 'ale', 'timestamp': [2.5999999046325684, 2.740000009536743]},\n  {'text': 'proszę', 'timestamp': [2.819999933242798, 3.4600000381469727]},\n  {'text': 'widzę', 'timestamp': [3.740000009536743, 3.9800000190734863]},\n  {'text': 'że', 'timestamp': [4.039999961853027, 4.139999866485596]},\n  {'text': 'wszyscy', 'timestamp': [4.179999828338623, 4.559999942779541]},\n  {'text': 'mamy', 'timestamp': [4.599999904632568, 4.840000152587891]},\n  {'text': 'już', 'timestamp': [4.860000133514404, 4.920000076293945]},\n  {'text': 'karty', 'timestamp': [4.940000057220459, 5.159999847412109]},\n  {'text': 'do', 'timestamp': [5.199999809265137, 5.260000228881836]},\n  {'text': 'głosowania', 'timestamp': [5.320000171661377, 5.800000190734863]},\n  {'text': 'w', 'timestamp': [5.820000171661377, 5.840000152587891]},\n  {'text': 'związku', 'timestamp': [5.880000114440918, 6.199999809265137]},\n  {'text': 'z', 'timestamp': [6.21999979019165, 6.239999771118164]},\n  {'text': 'tym', 'timestamp': [6.300000190734863, 6.420000076293945]},\n  {'text': 'poddam', 'timestamp': [6.5, 6.840000152587891]},\n  {'text': 'ten', 'timestamp': [6.880000114440918, 7.0]},\n  {'text': 'wniosek', 'timestamp': [7.039999961853027, 7.960000038146973]},\n  {'text': 'pod', 'timestamp': [8.020000457763672, 8.180000305175781]},\n  {'text': 'głosowanie', 'timestamp': [8.199999809265137, 8.699999809265137]},\n  {'text': 'kto', 'timestamp': [8.739999771118164, 8.880000114440918]},\n  {'text': 'z', 'timestamp': [8.9399995803833, 8.960000038146973]},\n  {'text': 'pań', 'timestamp': [9.020000457763672, 9.15999984741211]},\n  {'text': 'i', 'timestamp': [9.199999809265137, 9.220000267028809]},\n  {'text': 'panów', 'timestamp': [9.279999732971191, 9.479999542236328]},\n  {'text': 'posłów', 'timestamp': [9.539999961853027, 9.779999732971191]},\n  {'text': 'jest', 'timestamp': [9.800000190734863, 9.899999618530273]},\n  {'text': 'za', 'timestamp': [9.920000076293945, 10.020000457763672]},\n  {'text': 'ogłoszeniem',\n   'timestamp': [10.039999961853027, 10.979999542236328]},\n  {'text': 'przerwy', 'timestamp': [11.039999961853027, 11.380000114440918]},\n  {'text': 'w', 'timestamp': [11.420000076293945, 11.460000038146973]},\n  {'text': 'obradach', 'timestamp': [11.5, 11.84000015258789]},\n  {'text': 'zechce', 'timestamp': [12.020000457763672, 12.140000343322754]},\n  {'text': 'podnieść', 'timestamp': [12.15999984741211, 12.600000381469727]},\n  {'text': 'rękę', 'timestamp': [12.640000343322754, 12.880000114440918]},\n  {'text': 'i', 'timestamp': [12.920000076293945, 12.960000038146973]},\n  {'text': 'nacisnąć', 'timestamp': [12.979999542236328, 13.479999542236328]},\n  {'text': 'przycisk', 'timestamp': [13.520000457763672, 13.9399995803833]},\n  {'text': 'kto', 'timestamp': [14.0, 14.180000305175781]},\n  {'text': 'jest', 'timestamp': [14.220000267028809, 14.380000114440918]},\n  {'text': 'przeciw', 'timestamp': [14.460000038146973, 14.84000015258789]},\n  {'text': 'kto', 'timestamp': [14.880000114440918, 15.0]},\n  {'text': 'się', 'timestamp': [15.039999961853027, 15.119999885559082]},\n  {'text': 'wstrzymał', 'timestamp': [15.15999984741211, 15.920000076293945]},\n  {'text': 'głosowało', 'timestamp': [20.440000534057617, 21.5]},\n  {'text': 'czterysta', 'timestamp': [21.540000915527344, 21.899999618530273]},\n  {'text': 'czterdzieści',\n   'timestamp': [21.940000534057617, 22.260000228881836]},\n  {'text': 'dwa', 'timestamp': [22.299999237060547, 22.459999084472656]},\n  {'text': 'posłów', 'timestamp': [22.520000457763672, 22.860000610351562]},\n  {'text': 'za', 'timestamp': [22.920000076293945, 23.079999923706055]},\n  {'text': 'było', 'timestamp': [23.100000381469727, 23.239999771118164]},\n  {'text': 'sto', 'timestamp': [23.299999237060547, 23.459999084472656]},\n  {'text': 'osiemdziesiąt', 'timestamp': [23.5, 24.040000915527344]},\n  {'text': 'dziewięć', 'timestamp': [24.059999465942383, 24.479999542236328]},\n  {'text': 'przeciw', 'timestamp': [24.540000915527344, 24.860000610351562]},\n  {'text': 'dwieście', 'timestamp': [24.899999618530273, 25.18000030517578]},\n  {'text': 'czterdzieści',\n   'timestamp': [25.200000762939453, 25.639999389648438]},\n  {'text': 'siedem', 'timestamp': [25.700000762939453, 25.940000534057617]},\n  {'text': 'sześć', 'timestamp': [26.020000457763672, 26.280000686645508]},\n  {'text': 'się', 'timestamp': [26.34000015258789, 26.479999542236328]},\n  {'text': 'wstrzymało',\n   'timestamp': [26.520000457763672, 27.540000915527344]},\n  {'text': 'wniosek', 'timestamp': [27.559999465942383, 28.0]},\n  {'text': 'przepadł', 'timestamp': [28.059999465942383, 28.479999542236328]},\n  {'text': 'został', 'timestamp': [28.5, 28.6200008392334]},\n  {'text': 'odrzucony', 'timestamp': [28.639999389648438, 28.81999969482422]},\n  {'text': 'przegrali', 'timestamp': [28.84000015258789, 29.020000457763672]},\n  {'text': 'brawo', 'timestamp': [29.040000915527344, 29.139999389648438]},\n  {'text': 'brawo', 'timestamp': [29.15999984741211, 29.260000228881836]},\n  {'text': 'panie', 'timestamp': [29.280000686645508, 29.399999618530273]},\n  {'text': 'i', 'timestamp': [29.420000076293945, 29.440000534057617]},\n  {'text': 'panowie', 'timestamp': [29.5, 29.780000686645508]},\n  {'text': 'posłowie', 'timestamp': [29.84000015258789, 30.420000076293945]},\n  {'text': 'prezydium', 'timestamp': [30.479999542236328, 30.899999618530273]},\n  {'text': 'sejmu', 'timestamp': [30.940000534057617, 31.18000030517578]},\n  {'text': 'przedłożyło',\n   'timestamp': [31.219999313354492, 31.739999771118164]},\n  {'text': 'projekt', 'timestamp': [31.799999237060547, 32.119998931884766]},\n  {'text': 'uchwały', 'timestamp': [32.15999984741211, 32.459999084472656]},\n  {'text': 'w', 'timestamp': [32.5, 32.52000045776367]},\n  {'text': 'sprawie', 'timestamp': [32.560001373291016, 32.880001068115234]},\n  {'text': 'ustalenia', 'timestamp': [32.91999816894531, 33.41999816894531]},\n  {'text': 'liczby', 'timestamp': [33.459999084472656, 33.7400016784668]},\n  {'text': 'członków', 'timestamp': [33.779998779296875, 34.220001220703125]},\n  {'text': 'komisji', 'timestamp': [34.279998779296875, 34.65999984741211]},\n  {'text': 'do', 'timestamp': [34.720001220703125, 34.779998779296875]},\n  {'text': 'spraw', 'timestamp': [34.84000015258789, 35.099998474121094]},\n  {'text': 'służb', 'timestamp': [35.13999938964844, 35.459999084472656]}]}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T20:59:25.525746713Z",
     "start_time": "2023-07-21T20:59:25.479718462Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To correct the times, we will need the mask used for extracting the segment as well as sampling frequency (to be able to match the samples from the mask to the time in seconds)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'text': 'jeszcze', 'timestamp': [659.6179375, 659.7579374968708]},\n {'text': 'moment', 'timestamp': [659.778, 659.8980000047684]},\n {'text': 'jeszcze', 'timestamp': [659.9179375, 660.0779374964237]},\n {'text': 'moment', 'timestamp': [660.1179375, 660.3579375095368]},\n {'text': 'dobrze', 'timestamp': [660.398, 660.8180000166893]},\n {'text': 'to', 'timestamp': [660.8579375, 660.9179375619889]},\n {'text': 'jeszcze', 'timestamp': [660.938, 661.0979999666214]},\n {'text': 'chwileczkę', 'timestamp': [661.1179375, 661.4779375143052]},\n {'text': 'poczekamy', 'timestamp': [661.538, 662.1579998855591]},\n {'text': 'ale', 'timestamp': [662.1979375, 662.3379376049041]},\n {'text': 'proszę', 'timestamp': [662.4179375, 663.0579376049042]},\n {'text': 'widzę', 'timestamp': [667.982, 668.2220000095367]},\n {'text': 'że', 'timestamp': [668.2819375, 668.3819374046326]},\n {'text': 'wszyscy', 'timestamp': [668.4219375, 668.8019376144409]},\n {'text': 'mamy', 'timestamp': [668.8419375, 669.0819377479553]},\n {'text': 'już', 'timestamp': [669.102, 669.1619999427795]},\n {'text': 'karty', 'timestamp': [669.182, 669.4019997901917]},\n {'text': 'do', 'timestamp': [669.4419375, 669.5019379196167]},\n {'text': 'głosowania', 'timestamp': [669.562, 670.0420000190735]},\n {'text': 'w', 'timestamp': [670.062, 670.0819999809265]},\n {'text': 'związku', 'timestamp': [670.122, 670.4419996948242]},\n {'text': 'z', 'timestamp': [670.4619375, 670.4819374809265]},\n {'text': 'tym', 'timestamp': [670.542, 670.6619998855591]},\n {'text': 'poddam', 'timestamp': [670.7419375, 671.0819376525878]},\n {'text': 'ten', 'timestamp': [671.122, 671.241999885559]},\n {'text': 'wniosek', 'timestamp': [671.2819375, 672.201937576294]},\n {'text': 'pod', 'timestamp': [672.262, 672.421999847412]},\n {'text': 'głosowanie', 'timestamp': [672.4419375, 672.9419375]},\n {'text': 'kto', 'timestamp': [672.9819375, 673.1219378433227]},\n {'text': 'z', 'timestamp': [673.1819375, 673.2019379577637]},\n {'text': 'pań', 'timestamp': [673.262, 673.4019993896484]},\n {'text': 'i', 'timestamp': [673.4419375, 673.4619379577637]},\n {'text': 'panów', 'timestamp': [673.5219375, 673.7219373092652]},\n {'text': 'posłów', 'timestamp': [673.7819375, 674.0219372711182]},\n {'text': 'jest', 'timestamp': [674.042, 674.1419994277954]},\n {'text': 'za', 'timestamp': [674.162, 674.2620003814698]},\n {'text': 'ogłoszeniem', 'timestamp': [674.2819375, 675.2219370803833]},\n {'text': 'przerwy', 'timestamp': [675.2819375, 675.6219376525879]},\n {'text': 'w', 'timestamp': [675.662, 675.7019999618531]},\n {'text': 'obradach', 'timestamp': [675.7419375, 676.0819376525878]},\n {'text': 'zechce', 'timestamp': [676.262, 676.381999885559]},\n {'text': 'podnieść', 'timestamp': [676.4019375, 676.8419380340576]},\n {'text': 'rękę', 'timestamp': [676.882, 677.1219997711181]},\n {'text': 'i', 'timestamp': [677.162, 677.2019999618531]},\n {'text': 'nacisnąć', 'timestamp': [677.2219375, 677.7219375]},\n {'text': 'przycisk', 'timestamp': [677.762, 678.1819991226196]},\n {'text': 'kto', 'timestamp': [678.2419375, 678.4219378051757]},\n {'text': 'jest', 'timestamp': [678.462, 678.6219998474121]},\n {'text': 'przeciw', 'timestamp': [678.702, 679.0820001144409]},\n {'text': 'kto', 'timestamp': [679.122, 679.241999885559]},\n {'text': 'się', 'timestamp': [679.2819375, 679.3619374237061]},\n {'text': 'wstrzymał', 'timestamp': [679.4019375, 680.1619377288819]},\n {'text': 'głosowało', 'timestamp': [694.03, 695.0899994659424]},\n {'text': 'czterysta', 'timestamp': [695.53, 695.8899987030029]},\n {'text': 'czterdzieści', 'timestamp': [695.93, 696.2499996948242]},\n {'text': 'dwa', 'timestamp': [696.2899375, 696.4499373474121]},\n {'text': 'posłów', 'timestamp': [696.51, 696.8500001525879]},\n {'text': 'za', 'timestamp': [696.91, 697.0699998474121]},\n {'text': 'było', 'timestamp': [697.09, 697.2299993896485]},\n {'text': 'sto', 'timestamp': [697.2899375, 697.4499373474121]},\n {'text': 'osiemdziesiąt', 'timestamp': [697.4899375, 698.0299384155273]},\n {'text': 'dziewięć', 'timestamp': [698.0499375, 698.469937576294]},\n {'text': 'przeciw', 'timestamp': [698.53, 698.8499996948242]},\n {'text': 'dwieście', 'timestamp': [698.8899375, 699.1699381866455]},\n {'text': 'czterdzieści', 'timestamp': [699.19, 699.629998626709]},\n {'text': 'siedem', 'timestamp': [699.69, 699.9299997711182]},\n {'text': 'sześć', 'timestamp': [700.01, 700.2700002288818]},\n {'text': 'się', 'timestamp': [700.33, 700.4699993896485]},\n {'text': 'wstrzymało', 'timestamp': [700.51, 701.5300004577637]},\n {'text': 'wniosek', 'timestamp': [702.5939375, 703.0339380340577]},\n {'text': 'przepadł', 'timestamp': [703.0939375, 703.513937576294]},\n {'text': 'został', 'timestamp': [703.5339375, 703.6539383392334]},\n {'text': 'odrzucony', 'timestamp': [703.6739375, 703.8539378051757]},\n {'text': 'przegrali', 'timestamp': [703.874, 704.0540003051758]},\n {'text': 'brawo', 'timestamp': [704.074, 704.173998474121]},\n {'text': 'brawo', 'timestamp': [705.5259375, 705.6259378814698]},\n {'text': 'panie', 'timestamp': [705.646, 705.7659989318847]},\n {'text': 'i', 'timestamp': [705.786, 705.8060004577636]},\n {'text': 'panowie', 'timestamp': [705.8659375, 706.1459381866455]},\n {'text': 'posłowie', 'timestamp': [706.206, 706.7859999237061]},\n {'text': 'prezydium', 'timestamp': [706.8459375, 707.2659375762939]},\n {'text': 'sejmu', 'timestamp': [707.306, 707.5459997711182]},\n {'text': 'przedłożyło', 'timestamp': [707.5859375, 708.1059379577637]},\n {'text': 'projekt', 'timestamp': [708.1659375, 708.4859371948243]},\n {'text': 'uchwały', 'timestamp': [708.5259375, 708.8259367370606]},\n {'text': 'w', 'timestamp': [708.8659375, 708.8859379577636]},\n {'text': 'sprawie', 'timestamp': [708.926, 709.2459996948243]},\n {'text': 'ustalenia', 'timestamp': [709.2859375, 709.7859375]},\n {'text': 'liczby', 'timestamp': [709.8259375, 710.1059400939941]},\n {'text': 'członków', 'timestamp': [710.1459375, 710.5859399414062]},\n {'text': 'komisji', 'timestamp': [710.6459375, 711.0259385681152]},\n {'text': 'do', 'timestamp': [711.086, 711.1459975585938]},\n {'text': 'spraw', 'timestamp': [711.206, 711.4659983215332]},\n {'text': 'służb', 'timestamp': [711.5059375, 711.8259371948242]}]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali_words = list(ali.values())[0]\n",
    "\n",
    "ali_fixed = fix_times(ali_words, mask, audio['samp_freq'])\n",
    "ali_fixed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T20:59:25.615637092Z",
     "start_time": "2023-07-21T20:59:25.521529232Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Putting it all together\n",
    "\n",
    "Now let's repeat all of the above on the whole file. We have a single convenience method in the `Matcher` class that divides the file into chunks and computes the alignment of each chunk in sequence. The method requires the speech recognition word sequence, the audio file and speech recognition model (to do the alignment) as arguments.\n",
    "\n",
    "You can also optionally change the chunk length and stride. The stride allows for an overlap between chunks. After the chunks are aligned, any overlapping words are removed. The words are first sorted and the word with lower time is kept, while others are removed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/21/2023 22:59:25 [INFO] - Loading audio...\n",
      "07/21/2023 22:59:25 [INFO] - Making chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 60.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/21/2023 22:59:25 [INFO] - Aligning reference to audio...\n",
      "07/21/2023 22:59:25 [INFO] - Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/21/2023 22:59:37 [INFO] - Loading data...\n",
      "07/21/2023 22:59:37 [INFO] - Loaded 13 files!\n",
      "07/21/2023 22:59:37 [INFO] - Processing labels...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/13 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30eec4b9bbf9477280d9c404fb55815b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/21/2023 22:59:37 [INFO] - Total audio length: 1071.30s == 17.86min == 0.30h\n",
      "07/21/2023 22:59:37 [INFO] - Splitting data into chunks...\n",
      "Downloading and preparing dataset generator/default to /home/guest/.cache/huggingface/datasets/generator/default-94ee03569a4a2e6b/0.0.0...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "848d6642414f416394ec39e147a2ab40"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generator downloaded and prepared to /home/guest/.cache/huggingface/datasets/generator/default-94ee03569a4a2e6b/0.0.0. Subsequent calls will reuse this data.\n",
      "07/21/2023 22:59:38 [INFO] - Divided into 255 chunks!\n",
      "07/21/2023 22:59:38 [INFO] - Processing chunks using the W2V2 model...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/255 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2948b8ba451e4d739a695f8f76829fa9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/21/2023 23:01:38 [INFO] - Merging chunks back into files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:16<00:00, 15.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/21/2023 23:01:54 [INFO] - Performing forced alignment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/13 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61dcaccaea654fe0a3df4bf5ba0ad24d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/21/2023 23:01:57 [INFO] - Saving output...\n",
      "07/21/2023 23:01:57 [INFO] - Done!\n",
      "07/21/2023 23:01:57 [INFO] - Took 139.53s == 2.33min == 0.04h\n",
      "07/21/2023 23:01:57 [INFO] - Fixing times...\n",
      "07/21/2023 23:01:58 [INFO] - Removing overlapping words...\n"
     ]
    }
   ],
   "source": [
    "ali_all = matcher.run(words[utt_id], audio_file, asr_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T21:01:58.570756044Z",
     "start_time": "2023-07-21T20:59:25.615063263Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This will give us the alignment of the whole file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignemnt created 2478 aligned words.\n",
      "Sample of aligned words:\n",
      "[{'text': 'komendanta', 'timestamp': [599.8059375, 600.4059374791384], 'ref_pos': 81}, {'text': 'głównego', 'timestamp': [600.4659375, 600.9059375572205], 'ref_pos': 82}, {'text': 'policji', 'timestamp': [601.006, 601.8459999141693], 'ref_pos': 83}, {'text': 'zawierającą', 'timestamp': [603.0659375, 603.2859375286102], 'ref_pos': 84}, {'text': 'odpowiedź', 'timestamp': [603.3059375, 603.7459375572205], 'ref_pos': 85}, {'text': 'na', 'timestamp': [603.7659375, 603.845937423706], 'ref_pos': 86}, {'text': 'pytanie', 'timestamp': [603.926, 604.3259998569489], 'ref_pos': 87}, {'text': 'czy', 'timestamp': [604.426, 605.0260001430512], 'ref_pos': 88}, {'text': 'miasto', 'timestamp': [605.206, 605.5259996948242], 'ref_pos': 89}, {'text': 'wrocław', 'timestamp': [605.5659375, 606.1659374046326], 'ref_pos': 90}, {'text': 'należy', 'timestamp': [606.206, 606.5659996566773], 'ref_pos': 91}, {'text': 'jeszcze', 'timestamp': [606.6059375, 607.2659378242492], 'ref_pos': 92}, {'text': 'do', 'timestamp': [607.326, 607.826], 'ref_pos': 93}, {'text': 'rzeczypospolitej', 'timestamp': [607.866, 608.6459997329712], 'ref_pos': 94}, {'text': 'polskiej', 'timestamp': [608.746, 609.6259996376037], 'ref_pos': 95}, {'text': 'doniesienia', 'timestamp': [610.774, 611.4939993133545], 'ref_pos': 96}, {'text': 'z', 'timestamp': [611.554, 611.593999961853], 'ref_pos': 97}, {'text': 'ostatnich', 'timestamp': [611.6539375, 612.2739383392334], 'ref_pos': 98}, {'text': 'dni', 'timestamp': [612.354, 613.0139998474122], 'ref_pos': 99}, {'text': 'i', 'timestamp': [613.1739375, 613.3539378051757], 'ref_pos': 100}]\n"
     ]
    }
   ],
   "source": [
    "print(f'Alignemnt created {len(ali_all)} aligned words.')\n",
    "print(f'Sample of aligned words:\\n{ali_all[:20]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T21:02:15.257658755Z",
     "start_time": "2023-07-21T21:02:15.215486786Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now save the alignment to a TextGrid file. This is a popular format developed by the program called [Praat](www.praat.org) used for speech segmentation. It is used in many other tools, for example [Elan](https://archive.mpi.nl/tla/elan) and [EMU-webApp](https://ips-lmu.github.io/EMU-webApp/). Note that these tools may not work well with very long files. Praat supports loading long audio files, but its interface is quite dated. EMU is more modern, but works in the browser and could crash with loading a large audio file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "save_ali_to_textgrid(textgrid_file, ali_all)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T21:02:32.050806224Z",
     "start_time": "2023-07-21T21:02:31.865516353Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For actual debugging, we actually convert the word segmentation into kind of utterance segmentation by combining all the words that are close to each other into one utterance. We use the optional `sil_gap` argument to control the length of silence needed to make a new utterance. In some cases you may also want to use the `max_len` argument to further split long utterances into smaller chunks - this will be done in such a way that each sub-utterance is rougly same length, but none are longer than `max_len`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "segs = convert_ali_to_segments(ali_all, words[utt_id])\n",
    "\n",
    "with open(segs_file, 'w') as f:\n",
    "    json.dump(segs, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T21:02:38.950791123Z",
     "start_time": "2023-07-21T21:02:38.919553873Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once we save these chunks into a JSON file, we can use the provided HTML page to view the segmentation in your browser. The page will look for `audio.mp3` and `segs.json`. For the page to work, it should be hosted by an HTTP server (accessing the file locally won't work for security reasons). Furthermore, it is recommended to use a proper web server, rather than something like the `http.server` module in Python, because this will allow seeking in long audio files.\n",
    "\n",
    "The simplest solution for me is to use Docker. Simply run the following command in your terminal:\n",
    "\n",
    "```bash\n",
    "docker run -it --rm -p 8080:80 --name web -v ${PAGE_PATH}:/usr/share/nginx/html nginx\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Replace the `${PAGE_PATH}` with the absolute path of the directory containing the HTML page, the audio file and the utterance JSON. This will run the server that you can access in your browser at [http://localhost:8080/viewer.html](http://localhost:8080/viewer.html)."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
