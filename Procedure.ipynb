{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Explanation of the alignment procedure\n",
    "### for aligning very long audio sequences to very long text sequences\n",
    "\n",
    "This notebook describes the code for aligning long audio files to long text sequences using Huggingface Transformers toolkit.\n",
    "\n",
    "More precisely, we have the following inputs:\n",
    "* a long audio file (this can be anything from a few minutes, to a few hours, to a whole day of audio)\n",
    "* a text that contains the transcripts of the audio file\n",
    "\n",
    "On output we expect to get:\n",
    "* timecodes of portions of text to the portions of audio - word level timings\n",
    "\n",
    "Keeping in mind that:\n",
    "* audio can contain speech and events that aren't in the transcription\n",
    "* transcripts can contain text that isn't in the audio\n",
    "\n",
    "The sources of these discrepancies can be:\n",
    "* the transcript can be much larger than the speech contained in audio - in other words, we can have one large file with transcripts of many audio files and this is acceptable for this project - we only use what we need\n",
    "* the audio doesn't have to be transcribed with 100% recall or precision - transcribers make mistakes, not everything gets transcribed - this is all fine and we take it into account\n",
    "* the alignment process can produce errors - we have a procedure that allows for reviewing results and deciding on mitigation procedures after all the automation is complete\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from src.align import align, fix_times, save_ali_to_textgrid, convert_ali_to_segments\n",
    "from src.data_loaders import load_reco, load_audio, extract_audio\n",
    "from src.matching import Matcher\n",
    "from src.recognize import recognize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we define a couple of paths to local resources:\n",
    "* `audio_file` - the audio file containing the speech we wish to align to\n",
    "* `text_file` - the file containing all the transcripts - needs to contain text only and ideally should be normalized\n",
    "* `asr_model` - Huggingface hub name or path to the speech recognition model used to process the files\n",
    "\n",
    "These files are created throughout the procedure:\n",
    "* `reco_file`  - this file is the result of the initial speech recognition process\n",
    "* `textgrid_file`  - this file contains the final alignment openable in Praat and similar programs\n",
    "* `segs_file`  - this file contains the aligned segments useful for debugging and analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "audio_file = Path('data/0XpZGGwDkN8.wav')\n",
    "text_file = Path('data/201923-sjm-ppxxx-00010-02_norm.txt')\n",
    "asr_model = 'asr_model'\n",
    "reco_file = Path('data/reco.json')\n",
    "textgrid_file = Path('data/out.TextGrid')\n",
    "segs_file = Path('website/segs.json')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1 - Speech recognition\n",
    "\n",
    "The first step is to get any kind of speech recognition output that we can then use to align to actual transcripts.\n",
    "\n",
    "Since this process can be expensive, we will save the result immediately to a file. If the file exists, we don't have to run it again.\n",
    "\n",
    "It's also a good idea to restart the notebook kernel after running this cell in order to release memory on the GPU. Huggingface doesn't have a convenient method of releasing reserved resources and terminating the process is the simplest and most elegant way to achieve this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/19/2023 19:34:57 [INFO] - Loading data...\n",
      "03/19/2023 19:34:57 [WARNING] - Using custom data configuration default-d52fe6b6c670198b\n",
      "03/19/2023 19:34:57 [WARNING] - Found cached dataset generator (/home/guest/.cache/huggingface/datasets/generator/default-d52fe6b6c670198b/0.0.0)\n",
      "03/19/2023 19:34:57 [INFO] - Loaded 1 files!\n",
      "03/19/2023 19:34:57 [WARNING] - Using custom data configuration default-4e15d28221df04a9\n",
      "03/19/2023 19:34:57 [WARNING] - Found cached dataset generator (/home/guest/.cache/huggingface/datasets/generator/default-4e15d28221df04a9/0.0.0)\n",
      "03/19/2023 19:34:57 [WARNING] - Loading cached processed dataset at /home/guest/.cache/huggingface/datasets/generator/default-4e15d28221df04a9/0.0.0/cache-49a2ac608c887ccb.arrow\n",
      "03/19/2023 19:34:57 [INFO] - Obtained 75 segments!\n",
      "03/19/2023 19:34:57 [INFO] - Loading ASR model...\n",
      "03/19/2023 19:35:11 [INFO] - Starting recognition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:46<00:00,  1.61it/s]\n"
     ]
    }
   ],
   "source": [
    "if not reco_file.exists():\n",
    "    reco = recognize(audio_file, asr_model, batch_size=4)\n",
    "    with open(reco_file, 'w') as f:\n",
    "        json.dump(reco, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we re-load the above saved file. In the case of this demo, this will contain words belonging to only one recording, but theoretically you could recognize many recordings at once and the file would contain all of them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words per recording:\n",
      "{'0XpZGGwDkN8': 1653}\n"
     ]
    }
   ],
   "source": [
    "words = load_reco(reco_file)\n",
    "\n",
    "print('Number of words per recording:')\n",
    "print({x: len(y) for x, y in words.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we will first get the utterance id of the single file in question and then extract the first 100 words in the file. The idea of the procedure is to work in chunks to optimize the resources required for processing. We will first demonstrate the whole procedure on a single chunk and later show how to process the whole file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk len: 361.44399999999996s\n",
      "Chunk text:\n",
      "wznawiam obrady i przystąpimy do stwierdzenia kworum proszę zatem o naciśnięcie jakiegokolwiek przycisku celu potwierdzenia obecności a posiedzeniu dziękuję o obecnej es obecnych jest czterystu trzydziestu dziewięciu posłów stwierdzam kworum informuję że senat przyjął bez poprawek ustawy o szczególnych rozwiązaniach wspierających realizację programów operacyjnych w związku z wystąpieniem kowid dziewiętnaście w dwa tysiące dwudziestym roku w związku z tym planowany punkt dwunasty porządku dziennego stały się bez przedmiotowy z wnioskiem formalnym pan poseł grzegożbrałn konfederacj proszę bardzo minutę wieczór pani marszałek wysoka izbo no ktoś to jednak musi powiedzieć że że moglibyście państwo robić to inaczej mogłaby pani marszałek teraz\n"
     ]
    }
   ],
   "source": [
    "utt_id = list(words.keys())[0]\n",
    "words_chunk = words[utt_id][0:100]\n",
    "\n",
    "print(f'Chunk len: {words_chunk[-1].end - words_chunk[0].start}s')\n",
    "text = ' '.join([x.text for x in words_chunk])\n",
    "print(f'Chunk text:\\n{text}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2 - matching reco text to transcription\n",
    "\n",
    "We begin by creating a `Matcher` object. This object requires the transcript file on initialization and can later be used to match various audio file speech recognition results to it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "matcher = Matcher(text_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the beginning we match the above 100 word text to the whole transcript in a rough manner. This is done by making a histogram of the recognized word sequence and matching it to the histogram of the sliding window of same length across the whole transcript - akin to the BOW model of. A list of candidates that are sufficiently similar are returned at output. This can be controlled by the optional `threshold` argument."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 potential locations for the above text.\n"
     ]
    }
   ],
   "source": [
    "locs = matcher._initial_match(text)\n",
    "print(f'Found {len(locs)} potential locations for the above text.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "All the potential candidates are then compared to the original text using the Levenshtein distance method. This gives the exact score of all the differences between the two texts. That method is much more accurate, but also considerably more expensive than the one used in the inital match above. On output, we get both the best location and the difference between the two texts. The distance of 0 means the texts are identical. The higer the value to worse the match."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The location with minimum Levenshtein distance is 22261 and that distance is 105.\n"
     ]
    }
   ],
   "source": [
    "min_i, min_d = matcher._find_min_diff(locs, text)\n",
    "print(f'The location with minimum Levenshtein distance is {min_i} and that distance is {min_d}.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, the above method will only give us a starting location of the two texts, but given the nature of the speech recognition output and the transcript, these don't have to match in length. That is why we look for identically matching words to align the texts and reject any insertions/deletions at the beginning and the end of the sequence. The result is a set of two tuples containing both the begining and end of the speech recognition as well as the transcription portion of the text."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best matching sequence is between 0 and 100 in the recognized text and 22261 and 22357 in the reference corpus.\n"
     ]
    }
   ],
   "source": [
    "(hb, he), (rb, re) = matcher._find_matching_seq(text, min_i)\n",
    "\n",
    "print(f'The best matching sequence is between {hb} and {he} in the recognized text '\n",
    "      f'and {min_i + rb} and {min_i + re} in the reference corpus.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Having all that we can now match the transcription text to the ASR text which allows us also to get the time location of the transcription chunk within the audio file:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position of the text in audio file data/0XpZGGwDkN8.wav is between seconds 1009.192 and 1370.636.\n",
      "Recognized text:\n",
      "wznawiam obrady i przystąpimy do stwierdzenia kworum proszę zatem o naciśnięcie jakiegokolwiek przycisku celu potwierdzenia obecności a posiedzeniu dziękuję o obecnej es obecnych jest czterystu trzydziestu dziewięciu posłów stwierdzam kworum informuję że senat przyjął bez poprawek ustawy o szczególnych rozwiązaniach wspierających realizację programów operacyjnych w związku z wystąpieniem kowid dziewiętnaście w dwa tysiące dwudziestym roku w związku z tym planowany punkt dwunasty porządku dziennego stały się bez przedmiotowy z wnioskiem formalnym pan poseł grzegożbrałn konfederacj proszę bardzo minutę wieczór pani marszałek wysoka izbo no ktoś to jednak musi powiedzieć że że moglibyście państwo robić to inaczej mogłaby pani marszałek teraz\n",
      "Reference text:\n",
      "wznawiam obrady przystąpimy do stwierdzenia kworum proszę zatem o naciśnięcie jakiegokolwiek przycisku w celu potwierdzenia obecności na posiedzeniu obecnych jest czterysta trzydzieści dziewięć posłów stwierdzam kworum informuję że senat przyjął bez poprawek ustawę o szczególnych rozwiązaniach wspierających realizację programów operacyjnych w związku z wystąpieniem kovid dziewiętnaście w dwa tysiące dwadzieścia rok w związku z tym planowany punkt dwanaście porządku dziennego stał się bezprzedmiotowy z wnioskiem formalnym pan poseł grzegorz braun konfederacja proszę bardzo jeden minuta dobry wieczór pani marszałek wysoka izbo ktoś to jednak musi powiedzieć że moglibyście państwo robić to inaczej mogłaby pani marszałek teraz\n"
     ]
    }
   ],
   "source": [
    "hyp_text = ' '.join(text.split()[hb:he])\n",
    "hyp_tb = words_chunk[hb].start\n",
    "hyp_te = words_chunk[he - 1].end\n",
    "ref_text = matcher.get_corpus_chunk(min_i + rb, min_i + re)\n",
    "\n",
    "print(f'Position of the text in audio file {audio_file} is between seconds {hyp_tb} and {hyp_te}.')\n",
    "print(f'Recognized text:\\n{hyp_text}')\n",
    "print(f'Reference text:\\n{ref_text}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can then extract the audio within this segment. Now, this audio can also contain lots of silence which affects the performance of the alignment below. That is why we extract only the portions of the audio that match the words recognized by the ASR. This should contain all the audio that contains any speech within this segment.\n",
    "\n",
    "We also get the bit-mask matching the extracted segments. This will allow us to recreate the times in the original file, before removing the silences."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the extracted segment is 43.9800625s.\n"
     ]
    }
   ],
   "source": [
    "audio = load_audio(audio_file)\n",
    "seg, mask = extract_audio(audio['input_values'], words_chunk[hb:he], audio['samp_freq'])\n",
    "\n",
    "print(f'The length of the extracted segment is {len(seg) / audio[\"samp_freq\"]}s.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3 - Re-alignment\n",
    "\n",
    "The above text matching procedure only gave us the beginning and end of the whole segment. If we want to get a more accurate alignment we need to re-align all the words from the reference transcription to the audio. Fortunately, this procedure is quite robust given the limited number of words and length of audio extracted above.\n",
    "\n",
    "It is worth noting, however, that any errors and inaccuracies in the transcript will cause unexpected behavior in the final output.\n",
    "\n",
    "Note that this method accepts a whole sequence of audio/text pairs. Here we only have one, so we will put both in a single element list each."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20928b792d574ccab42068345c325f74"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/19/2023 19:36:11 [WARNING] - Using custom data configuration default-f7a466021063490e\n",
      "03/19/2023 19:36:11 [WARNING] - Found cached dataset generator (/home/guest/.cache/huggingface/datasets/generator/default-f7a466021063490e/0.0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff4b7c97b8b3484fa74d424a1151cfa1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1ef0922166349c591498cc13815d733"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ali = align(asr_model, [seg], [ref_text])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is what the result looks like. It's a list of words, with a begin/end timestamp for each one. Note that the times provided are within the extracted segment only. To get the times that match the original file, we need to make some corrections."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "{'audio_0000': [{'text': 'wznawiam',\n   'timestamp': [0.23999999463558197, 0.6800000071525574]},\n  {'text': 'obrady', 'timestamp': [0.699999988079071, 1.4800000190734863]},\n  {'text': 'przystąpimy',\n   'timestamp': [1.6200000047683716, 2.180000066757202]},\n  {'text': 'do', 'timestamp': [2.2200000286102295, 2.2799999713897705]},\n  {'text': 'stwierdzenia',\n   'timestamp': [2.319999933242798, 2.940000057220459]},\n  {'text': 'kworum', 'timestamp': [3.0, 3.4000000953674316]},\n  {'text': 'proszę', 'timestamp': [3.440000057220459, 3.700000047683716]},\n  {'text': 'zatem', 'timestamp': [3.759999990463257, 4.059999942779541]},\n  {'text': 'o', 'timestamp': [4.099999904632568, 4.159999847412109]},\n  {'text': 'naciśnięcie', 'timestamp': [4.199999809265137, 4.78000020980835]},\n  {'text': 'jakiegokolwiek',\n   'timestamp': [4.800000190734863, 5.400000095367432]},\n  {'text': 'przycisku', 'timestamp': [5.460000038146973, 6.28000020980835]},\n  {'text': 'w', 'timestamp': [6.300000190734863, 6.340000152587891]},\n  {'text': 'celu', 'timestamp': [6.400000095367432, 6.579999923706055]},\n  {'text': 'potwierdzenia',\n   'timestamp': [6.639999866485596, 7.159999847412109]},\n  {'text': 'obecności', 'timestamp': [7.179999828338623, 7.699999809265137]},\n  {'text': 'na', 'timestamp': [7.739999771118164, 7.820000171661377]},\n  {'text': 'posiedzeniu', 'timestamp': [7.880000114440918, 8.819999694824219]},\n  {'text': 'obecnych', 'timestamp': [10.239999771118164, 10.600000381469727]},\n  {'text': 'jest', 'timestamp': [11.640000343322754, 11.800000190734863]},\n  {'text': 'czterysta', 'timestamp': [11.859999656677246, 12.220000267028809]},\n  {'text': 'trzydzieści',\n   'timestamp': [12.239999771118164, 12.520000457763672]},\n  {'text': 'dziewięć', 'timestamp': [12.539999961853027, 12.899999618530273]},\n  {'text': 'posłów', 'timestamp': [12.979999542236328, 13.399999618530273]},\n  {'text': 'stwierdzam', 'timestamp': [13.4399995803833, 14.319999694824219]},\n  {'text': 'kworum', 'timestamp': [14.399999618530273, 15.239999771118164]},\n  {'text': 'informuję', 'timestamp': [15.260000228881836, 15.760000228881836]},\n  {'text': 'że', 'timestamp': [15.800000190734863, 15.880000114440918]},\n  {'text': 'senat', 'timestamp': [15.920000076293945, 16.219999313354492]},\n  {'text': 'przyjął', 'timestamp': [16.260000228881836, 16.5]},\n  {'text': 'bez', 'timestamp': [16.540000915527344, 16.68000030517578]},\n  {'text': 'poprawek', 'timestamp': [16.700000762939453, 17.079999923706055]},\n  {'text': 'ustawę', 'timestamp': [17.1200008392334, 17.399999618530273]},\n  {'text': 'o', 'timestamp': [17.420000076293945, 17.440000534057617]},\n  {'text': 'szczególnych',\n   'timestamp': [17.479999542236328, 17.8799991607666]},\n  {'text': 'rozwiązaniach',\n   'timestamp': [17.899999618530273, 18.420000076293945]},\n  {'text': 'wspierających', 'timestamp': [18.440000534057617, 19.0]},\n  {'text': 'realizację',\n   'timestamp': [19.040000915527344, 19.520000457763672]},\n  {'text': 'programów', 'timestamp': [19.559999465942383, 19.959999084472656]},\n  {'text': 'operacyjnych',\n   'timestamp': [19.979999542236328, 20.459999084472656]},\n  {'text': 'w', 'timestamp': [20.479999542236328, 20.5]},\n  {'text': 'związku', 'timestamp': [20.540000915527344, 20.8799991607666]},\n  {'text': 'z', 'timestamp': [20.920000076293945, 20.940000534057617]},\n  {'text': 'wystąpieniem',\n   'timestamp': [20.959999084472656, 21.440000534057617]},\n  {'text': 'kovid', 'timestamp': [21.5, 21.700000762939453]},\n  {'text': 'dziewiętnaście',\n   'timestamp': [21.719999313354492, 22.760000228881836]},\n  {'text': 'w', 'timestamp': [22.780000686645508, 22.81999969482422]},\n  {'text': 'dwa', 'timestamp': [22.860000610351562, 22.979999542236328]},\n  {'text': 'tysiące', 'timestamp': [23.040000915527344, 23.34000015258789]},\n  {'text': 'dwadzieścia', 'timestamp': [23.3799991607666, 23.81999969482422]},\n  {'text': 'rok', 'timestamp': [23.860000610351562, 24.059999465942383]},\n  {'text': 'w', 'timestamp': [24.079999923706055, 24.100000381469727]},\n  {'text': 'związku', 'timestamp': [24.139999389648438, 24.479999542236328]},\n  {'text': 'z', 'timestamp': [24.5, 24.520000457763672]},\n  {'text': 'tym', 'timestamp': [24.579999923706055, 24.68000030517578]},\n  {'text': 'planowany', 'timestamp': [24.719999313354492, 25.1200008392334]},\n  {'text': 'punkt', 'timestamp': [25.18000030517578, 25.360000610351562]},\n  {'text': 'dwanaście', 'timestamp': [25.3799991607666, 25.739999771118164]},\n  {'text': 'porządku', 'timestamp': [25.780000686645508, 26.100000381469727]},\n  {'text': 'dziennego', 'timestamp': [26.139999389648438, 26.440000534057617]},\n  {'text': 'stał', 'timestamp': [26.479999542236328, 26.65999984741211]},\n  {'text': 'się', 'timestamp': [26.700000762939453, 26.780000686645508]},\n  {'text': 'bezprzedmiotowy',\n   'timestamp': [26.84000015258789, 28.079999923706055]},\n  {'text': 'z', 'timestamp': [28.15999984741211, 28.200000762939453]},\n  {'text': 'wnioskiem', 'timestamp': [28.260000228881836, 29.079999923706055]},\n  {'text': 'formalnym', 'timestamp': [29.1200008392334, 29.8799991607666]},\n  {'text': 'pan', 'timestamp': [29.940000534057617, 30.100000381469727]},\n  {'text': 'poseł', 'timestamp': [30.15999984741211, 30.520000457763672]},\n  {'text': 'grzegorz', 'timestamp': [30.559999465942383, 30.920000076293945]},\n  {'text': 'braun', 'timestamp': [31.0, 31.34000015258789]},\n  {'text': 'konfederacja',\n   'timestamp': [31.399999618530273, 32.08000183105469]},\n  {'text': 'proszę', 'timestamp': [32.119998931884766, 32.380001068115234]},\n  {'text': 'bardzo', 'timestamp': [32.41999816894531, 32.65999984741211]},\n  {'text': 'jeden', 'timestamp': [32.68000030517578, 32.779998779296875]},\n  {'text': 'minuta', 'timestamp': [32.79999923706055, 33.220001220703125]},\n  {'text': 'dobry', 'timestamp': [33.2400016784668, 33.459999084472656]},\n  {'text': 'wieczór', 'timestamp': [33.5, 33.91999816894531]},\n  {'text': 'pani', 'timestamp': [34.0, 34.220001220703125]},\n  {'text': 'marszałek', 'timestamp': [34.2400016784668, 35.36000061035156]},\n  {'text': 'wysoka', 'timestamp': [35.400001525878906, 35.91999816894531]},\n  {'text': 'izbo', 'timestamp': [35.97999954223633, 36.31999969482422]},\n  {'text': 'ktoś', 'timestamp': [36.959999084472656, 37.18000030517578]},\n  {'text': 'to', 'timestamp': [37.2400016784668, 37.34000015258789]},\n  {'text': 'jednak', 'timestamp': [37.36000061035156, 37.68000030517578]},\n  {'text': 'musi', 'timestamp': [37.720001220703125, 37.939998626708984]},\n  {'text': 'powiedzieć', 'timestamp': [38.0, 38.68000030517578]},\n  {'text': 'że', 'timestamp': [38.7400016784668, 39.2400016784668]},\n  {'text': 'moglibyście',\n   'timestamp': [39.459999084472656, 40.15999984741211]},\n  {'text': 'państwo', 'timestamp': [40.2400016784668, 40.58000183105469]},\n  {'text': 'robić', 'timestamp': [40.599998474121094, 40.880001068115234]},\n  {'text': 'to', 'timestamp': [40.91999816894531, 41.040000915527344]},\n  {'text': 'inaczej', 'timestamp': [41.08000183105469, 41.97999954223633]},\n  {'text': 'mogłaby', 'timestamp': [42.02000045776367, 42.47999954223633]},\n  {'text': 'pani', 'timestamp': [42.560001373291016, 42.779998779296875]},\n  {'text': 'marszałek', 'timestamp': [42.81999969482422, 43.36000061035156]},\n  {'text': 'teraz', 'timestamp': [43.41999816894531, 43.959999084472656]}]}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To correct the times, we will need the mask used for extracting the segment as well as sampling frequency (to be able to match the samples from the mask to the time in seconds)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'text': 'wznawiam', 'timestamp': [1009.1819375, 1009.621937512517]},\n {'text': 'obrady', 'timestamp': [1009.6419375, 1010.4219375309945]},\n {'text': 'przystąpimy', 'timestamp': [1010.562, 1011.1220000619888]},\n {'text': 'do', 'timestamp': [1011.162, 1011.2219999427796]},\n {'text': 'stwierdzenia', 'timestamp': [1011.2619375, 1011.8819376239777]},\n {'text': 'kworum', 'timestamp': [1011.9419375, 1012.3419375953674]},\n {'text': 'proszę', 'timestamp': [1012.382, 1012.6419999904632]},\n {'text': 'zatem', 'timestamp': [1012.7019375, 1013.0019374523163]},\n {'text': 'o', 'timestamp': [1013.0419375, 1013.1019374427796]},\n {'text': 'naciśnięcie', 'timestamp': [1013.1419375, 1013.7219379005433]},\n {'text': 'jakiegokolwiek', 'timestamp': [1013.742, 1014.3419999046325]},\n {'text': 'przycisku', 'timestamp': [1014.402, 1015.2220001716614]},\n {'text': 'w', 'timestamp': [1015.742, 1015.781999961853]},\n {'text': 'celu', 'timestamp': [1015.842, 1016.0219998283386]},\n {'text': 'potwierdzenia', 'timestamp': [1016.0819375, 1016.6019374809265]},\n {'text': 'obecności', 'timestamp': [1016.6219375, 1017.1419374809265]},\n {'text': 'na', 'timestamp': [1017.1819375, 1017.2619379005432]},\n {'text': 'posiedzeniu', 'timestamp': [1017.322, 1018.2619995803833]},\n {'text': 'obecnych', 'timestamp': [1320.6259375, 1320.9859381103515]},\n {'text': 'jest', 'timestamp': [1322.026, 1322.1859998474122]},\n {'text': 'czterysta', 'timestamp': [1322.2459375, 1322.6059381103516]},\n {'text': 'trzydzieści', 'timestamp': [1322.6259375, 1322.9059381866455]},\n {'text': 'dziewięć', 'timestamp': [1322.9259375, 1323.2859371566772]},\n {'text': 'posłów', 'timestamp': [1323.3659375, 1323.785937576294]},\n {'text': 'stwierdzam', 'timestamp': [1323.8259375, 1324.705937614441]},\n {'text': 'kworum', 'timestamp': [1324.7859375, 1325.625937652588]},\n {'text': 'informuję', 'timestamp': [1332.086, 1332.586]},\n {'text': 'że', 'timestamp': [1332.626, 1332.705999923706]},\n {'text': 'senat', 'timestamp': [1332.746, 1333.0459992370606]},\n {'text': 'przyjął', 'timestamp': [1333.086, 1333.3259997711182]},\n {'text': 'bez', 'timestamp': [1333.366, 1333.5059993896484]},\n {'text': 'poprawek', 'timestamp': [1333.526, 1333.9059991607667]},\n {'text': 'ustawę', 'timestamp': [1333.946, 1334.2259987792968]},\n {'text': 'o', 'timestamp': [1334.246, 1334.2660004577638]},\n {'text': 'szczególnych', 'timestamp': [1334.3059375, 1334.7059371185303]},\n {'text': 'rozwiązaniach', 'timestamp': [1334.7259375, 1335.2459379577638]},\n {'text': 'wspierających', 'timestamp': [1335.266, 1335.8259994659425]},\n {'text': 'realizację', 'timestamp': [1335.866, 1336.3459995422363]},\n {'text': 'programów', 'timestamp': [1336.3859375, 1336.7859371185302]},\n {'text': 'operacyjnych', 'timestamp': [1336.8059375, 1337.2859370422364]},\n {'text': 'w', 'timestamp': [1337.3059375, 1337.3259379577637]},\n {'text': 'związku', 'timestamp': [1337.366, 1337.7059982452392]},\n {'text': 'z', 'timestamp': [1337.746, 1337.7660004577638]},\n {'text': 'wystąpieniem', 'timestamp': [1337.7859375, 1338.265938949585]},\n {'text': 'kovid', 'timestamp': [1338.3259375, 1338.5259382629395]},\n {'text': 'dziewiętnaście', 'timestamp': [1338.5459375, 1339.5859384155274]},\n {'text': 'w', 'timestamp': [1340.074, 1340.1139990081788]},\n {'text': 'dwa', 'timestamp': [1340.154, 1340.2739989318848]},\n {'text': 'tysiące', 'timestamp': [1340.334, 1340.6339992370606]},\n {'text': 'dwadzieścia', 'timestamp': [1340.6739375, 1341.1139380340576]},\n {'text': 'rok', 'timestamp': [1341.154, 1341.3539988555908]},\n {'text': 'w', 'timestamp': [1341.3739375, 1341.3939379577637]},\n {'text': 'związku', 'timestamp': [1341.4339375, 1341.7739376525878]},\n {'text': 'z', 'timestamp': [1341.7939375, 1341.8139379577638]},\n {'text': 'tym', 'timestamp': [1341.8739375, 1341.9739378814697]},\n {'text': 'planowany', 'timestamp': [1342.0139375, 1342.413939025879]},\n {'text': 'punkt', 'timestamp': [1342.474, 1342.6540003051757]},\n {'text': 'dwanaście', 'timestamp': [1342.6739375, 1343.0339381103515]},\n {'text': 'porządku', 'timestamp': [1343.074, 1343.3939996948243]},\n {'text': 'dziennego', 'timestamp': [1343.4339375, 1343.7339386444091]},\n {'text': 'stał', 'timestamp': [1343.7739375, 1343.9539378051759]},\n {'text': 'się', 'timestamp': [1343.994, 1344.073999923706]},\n {'text': 'bezprzedmiotowy', 'timestamp': [1344.134, 1345.3739997711182]},\n {'text': 'z', 'timestamp': [1346.6419375, 1346.6819384155274]},\n {'text': 'wnioskiem', 'timestamp': [1346.742, 1347.5619996948242]},\n {'text': 'formalnym', 'timestamp': [1347.602, 1348.3619983215333]},\n {'text': 'pan', 'timestamp': [1348.422, 1348.5819998474121]},\n {'text': 'poseł', 'timestamp': [1348.6419375, 1349.0019381103516]},\n {'text': 'grzegorz', 'timestamp': [1349.0419375, 1349.4019381103515]},\n {'text': 'braun', 'timestamp': [1349.4819375, 1349.8219376525878]},\n {'text': 'konfederacja', 'timestamp': [1349.8819375, 1350.5619397125245]},\n {'text': 'proszę', 'timestamp': [1350.6019375, 1350.8619396362305]},\n {'text': 'bardzo', 'timestamp': [1350.9019375, 1351.1419391784668]},\n {'text': 'jeden', 'timestamp': [1351.162, 1351.2619984741211]},\n {'text': 'minuta', 'timestamp': [1351.2819375, 1351.7019394836425]},\n {'text': 'dobry', 'timestamp': [1351.722, 1351.9419974060058]},\n {'text': 'wieczór', 'timestamp': [1358.7339375, 1359.1539356689452]},\n {'text': 'pani', 'timestamp': [1359.2339375, 1359.453938720703]},\n {'text': 'marszałek', 'timestamp': [1359.474, 1360.5939989318847]},\n {'text': 'wysoka', 'timestamp': [1361.118, 1361.6379966430663]},\n {'text': 'izbo', 'timestamp': [1361.6979375, 1362.037937652588]},\n {'text': 'ktoś', 'timestamp': [1363.2379375, 1363.4579387207032]},\n {'text': 'to', 'timestamp': [1363.518, 1363.6179984741211]},\n {'text': 'jednak', 'timestamp': [1363.638, 1363.9579996948241]},\n {'text': 'musi', 'timestamp': [1363.998, 1364.217997406006]},\n {'text': 'powiedzieć', 'timestamp': [1364.2779375, 1364.9579378051758]},\n {'text': 'że', 'timestamp': [1365.018, 1365.518]},\n {'text': 'moglibyście', 'timestamp': [1366.365875, 1367.0658757629394]},\n {'text': 'państwo', 'timestamp': [1367.1459375, 1367.4859376525878]},\n {'text': 'robić', 'timestamp': [1367.505875, 1367.7858775939942]},\n {'text': 'to', 'timestamp': [1367.825875, 1367.945877746582]},\n {'text': 'inaczej', 'timestamp': [1367.9859375, 1368.8859352111817]},\n {'text': 'mogłaby', 'timestamp': [1368.9259375, 1369.3859365844726]},\n {'text': 'pani', 'timestamp': [1369.4659375, 1369.685934906006]},\n {'text': 'marszałek', 'timestamp': [1369.725875, 1370.2658759155274]},\n {'text': 'teraz', 'timestamp': [1370.325875, 1370.8658759155273]}]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali_words = list(ali.values())[0]\n",
    "\n",
    "ali_fixed = fix_times(ali_words, mask, audio['samp_freq'])\n",
    "ali_fixed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Putting it all together\n",
    "\n",
    "Now let's repeat all of the above on the whole file. We have a single convenience method in the `Matcher` class that divides the file into chunks and computes the alignment of each chunk in sequence. The method requires the speech recognition word sequence, the audio file and speech recognition model (to do the alignment) as arguments.\n",
    "\n",
    "You can also optionally change the chunk length and stride. The stride allows for an overlap between chunks. After the chunks are aligned, any overlapping words are removed. The words are first sorted and the word with lower time is kept, while others are removed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/9 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "face7b62a15b4a15a484f643491a21d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/19/2023 19:36:36 [WARNING] - Using custom data configuration default-3d36d39152042988\n",
      "03/19/2023 19:36:36 [WARNING] - Found cached dataset generator (/home/guest/.cache/huggingface/datasets/generator/default-3d36d39152042988/0.0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/41 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e8b174590514edcbc5b0acb8aedcc8d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:09<00:00, 16.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b61ccd90cb4a472092452afaaf4d4f0b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ali_all = matcher.run(words[utt_id], audio_file, asr_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This will give us the alignment of the whole file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignemnt created 1622 aligned words.\n",
      "Sample of aligned words:\n",
      "[{'text': 'wznawiam', 'timestamp': [1009.1819375, 1009.621937512517]}, {'text': 'obrady', 'timestamp': [1009.6419375, 1010.4219375309945]}, {'text': 'przystąpimy', 'timestamp': [1010.562, 1011.1220000619888]}, {'text': 'do', 'timestamp': [1011.162, 1011.2219999427796]}, {'text': 'stwierdzenia', 'timestamp': [1011.2619375, 1011.8819376239777]}, {'text': 'kworum', 'timestamp': [1011.9419375, 1012.3419375953674]}, {'text': 'proszę', 'timestamp': [1012.382, 1012.6419999904632]}, {'text': 'zatem', 'timestamp': [1012.7019375, 1013.0019374523163]}, {'text': 'o', 'timestamp': [1013.0419375, 1013.1019374427796]}, {'text': 'naciśnięcie', 'timestamp': [1013.1419375, 1013.7219379005433]}, {'text': 'jakiegokolwiek', 'timestamp': [1013.742, 1014.3419999046325]}, {'text': 'przycisku', 'timestamp': [1014.402, 1015.2220001716614]}, {'text': 'w', 'timestamp': [1015.742, 1015.781999961853]}, {'text': 'celu', 'timestamp': [1015.842, 1016.0219998283386]}, {'text': 'potwierdzenia', 'timestamp': [1016.0819375, 1016.6019374809265]}, {'text': 'obecności', 'timestamp': [1016.6219375, 1017.1419374809265]}, {'text': 'na', 'timestamp': [1017.1819375, 1017.2619379005432]}, {'text': 'posiedzeniu', 'timestamp': [1017.322, 1018.2619995803833]}, {'text': 'obecnych', 'timestamp': [1320.6259375, 1320.9859381103515]}, {'text': 'jest', 'timestamp': [1322.026, 1322.1859998474122]}]\n"
     ]
    }
   ],
   "source": [
    "print(f'Alignemnt created {len(ali_all)} aligned words.')\n",
    "print(f'Sample of aligned words:\\n{ali_all[:20]}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now save the alignment to a TextGrid file. This is a popular format developed by the program called [Praat](www.praat.org) used for speech segmentation. It is used in many other tools, for example [Elan](https://archive.mpi.nl/tla/elan) and [EMU-webApp](https://ips-lmu.github.io/EMU-webApp/). Note that these tools may not work well with very long files. Praat supports loading long audio files, but its interface is quite dated. EMU is more modern, but works in the browser and could crash with loading a large audio file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "save_ali_to_textgrid(textgrid_file, ali_all)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For actual debugging, we actually convert the word segmentation into kind of utterance segmentation by combining all the words that are close to each other into one utterance. We use the optional `sil_gap` argument to control the length of silence needed to make a new utterance. In some cases you may also want to use the `max_len` argument to further split long utterances into smaller chunks - this will be done in such a way that each sub-utterance is rougly same length, but none are longer than `max_len`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "segs = convert_ali_to_segments(ali_all, words[utt_id])\n",
    "\n",
    "with open(segs_file, 'w') as f:\n",
    "    json.dump(segs, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once we save these chunks into a JSON file, we can use the provided HTML page to view the segmentation in your browser. The page will look for `audio.mp3` and `segs.json`. For the page to work, it should be hosted by an HTTP server (accessing the file locally won't work for security reasons). Furthermore, it is recommended to use a proper web server, rather than something like the `http.server` module in Python, because this will allow seeking in long audio files.\n",
    "\n",
    "The simplest solution for me is to use Docker. Simply run the following command in your terminal:\n",
    "\n",
    "```bash\n",
    "docker run -it --rm -p 8080:80 --name web -v ${PAGE_PATH}:/usr/share/nginx/html nginx\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Replace the `${PAGE_PATH}` with the absolute path of the directory containing the HTML page, the audio file and the utterance JSON. This will run the server that you can access in your browser at [http://localhost:8080/viewer.html](http://localhost:8080/viewer.html)."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
